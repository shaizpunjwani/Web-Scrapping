{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c855d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip install autoscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb25457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoscraper import AutoScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4138955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['122', '60', '25', '68', '57', '22', '206', '140', '108', '291', '15', '33', '2', '174', '69', '71', '13', '12', '14', '29', '128', '56', '7', '79', '17', 'Car-Price-Prediction', 'Credit-Card-Fraudlent', 'Huggingfacetransformer', 'Malaria-Detection', 'Deep-Learning-Car-Brand', 'Image-Webscrapper', 'Deployment-flask', 'Feature-Engineering-Live-sessions', 'Advanced-House-Price-Prediction-', 'EDA1', 'Python-Practise-Problems', 'PysparkRegressions', 'Flask-Web-Framework', 'MediaPipe', 'Media-Pipe', 'Data-Analyst-Skill-With-Videos-in-2021', 'Deployment-Deep-Learning-Model', 'Stock-MArket-Forecasting', 'Heroku-Demo', 'Django-Series', 'stats-sessions', 'Image-Segmentation-Using-Pixellib', 'Flask-Heroku', 'Weather-Chatbot-Using-Luis', 'Natural-Language-Processing', 'Finding-an-Outlier', 'Pywebheroku', 'Trnasformer-Bert', 'Pyspark-With-Python', 'WaferFaultDetection']\n"
     ]
    }
   ],
   "source": [
    "#give the websites url for which you have to scrap\n",
    "url='https://github.com/krishnaik06?tab=repositories'\n",
    "#here we will be givig the list of the candidates or the features which we want in our file\n",
    "#so simply just give 2 feature here we have given the star number and repository name of just 1\n",
    "#so it will scrap all the name and star number\n",
    "wanted_lst=['122','Car-Price-Prediction']\n",
    "scraper=AutoScraper()\n",
    "#here build takes 2 parameters 1 is our url and second is the wanted_lst\n",
    "result=scraper.build(url, wanted_lst)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777fd10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rule_keuh': ['122',\n",
       "  '60',\n",
       "  '25',\n",
       "  '68',\n",
       "  '57',\n",
       "  '22',\n",
       "  '206',\n",
       "  '206',\n",
       "  '140',\n",
       "  '108',\n",
       "  '291',\n",
       "  '15',\n",
       "  '33',\n",
       "  '22',\n",
       "  '2',\n",
       "  '174',\n",
       "  '69',\n",
       "  '108',\n",
       "  '71',\n",
       "  '13',\n",
       "  '15',\n",
       "  '12',\n",
       "  '14',\n",
       "  '29',\n",
       "  '128',\n",
       "  '56',\n",
       "  '7',\n",
       "  '15',\n",
       "  '79',\n",
       "  '17'],\n",
       " 'rule_z0jc': ['Car-Price-Prediction',\n",
       "  'Credit-Card-Fraudlent',\n",
       "  'Huggingfacetransformer',\n",
       "  'Malaria-Detection',\n",
       "  'Deep-Learning-Car-Brand',\n",
       "  'Image-Webscrapper',\n",
       "  'Deployment-flask',\n",
       "  'Feature-Engineering-Live-sessions',\n",
       "  'Advanced-House-Price-Prediction-',\n",
       "  'EDA1',\n",
       "  'Python-Practise-Problems',\n",
       "  'PysparkRegressions',\n",
       "  'Flask-Web-Framework',\n",
       "  'MediaPipe',\n",
       "  'Media-Pipe',\n",
       "  'Data-Analyst-Skill-With-Videos-in-2021',\n",
       "  'Deployment-Deep-Learning-Model',\n",
       "  'Stock-MArket-Forecasting',\n",
       "  'Heroku-Demo',\n",
       "  'Django-Series',\n",
       "  'stats-sessions',\n",
       "  'Image-Segmentation-Using-Pixellib',\n",
       "  'Flask-Heroku',\n",
       "  'Weather-Chatbot-Using-Luis',\n",
       "  'Natural-Language-Processing',\n",
       "  'Finding-an-Outlier',\n",
       "  'Pywebheroku',\n",
       "  'Trnasformer-Bert',\n",
       "  'Pyspark-With-Python',\n",
       "  'WaferFaultDetection']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now till here we achived our scraper but now we will explore the grouping where we will be\n",
    "#generating the id in terms of dictionary were 1 key will be our star and 2 key will be title of repositires\n",
    "scraper.get_result_similar(url, grouped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "634c7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now here we got our disctionary based on our candidates but the key names are bit complicated\n",
    "#so we would be changing those\n",
    "#rule ko aliases kehete ha ab hum in aliases ki naam change krdeinge\n",
    "scraper.set_rule_aliases({'rule_keuh':'Stars', 'rule_z0jc': 'Title'})\n",
    "#here we would stating only those rules which we are required a list will be passed\n",
    "scraper.keep_rules(['rule_keuh', 'rule_z0jc'])\n",
    "scraper.save('github-repository-search')\n",
    "#till here we saved our autoscraper and this scraper will also be working on different \n",
    "#repositries as given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19704a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to try on different repo we will be first loading the scraper\n",
    "scraper.load('github-repository-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbaff6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving different repo link \n",
    "url1='https://github.com/iNeuronai?tab=repositories'\n",
    "result=scraper.get_result_similar(url1, group_by_alias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fbcbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interview-question-data-science-',\n",
       " 'webscrappper_text',\n",
       " 'chabot_video_codes',\n",
       " 'flaskWeatherApp',\n",
       " 'MachineLearningModelToPivotal',\n",
       " 'MachineLearningModelToAzure',\n",
       " 'MachineLearningModelToAWS',\n",
       " 'MachineLearningModelToGCP',\n",
       " 'MachineLearningModelToHeroku',\n",
       " 'same-resume-year-wise',\n",
       " 'sudhtest87435353',\n",
       " '-bigsparkrepo',\n",
       " 'deep-learning-drizzle',\n",
       " 'Ineuron-Arhcitecture',\n",
       " 'zomatoEDA',\n",
       " 'A',\n",
       " 'assignmentrepo',\n",
       " 'allMLProjects',\n",
       " 'TimeSeries',\n",
       " 'assignemnt-',\n",
       " 'code',\n",
       " 'xyz',\n",
       " 'waffer-project',\n",
       " 'DeepLearningDocs',\n",
       " 'DecisionTrees',\n",
       " 'PrincipalComponentAnalysis',\n",
       " 'Working-with-MongoDB',\n",
       " 'imageScrapper',\n",
       " 'Chatbots_using_Dialogflow',\n",
       " 'AzureWeatherBot']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Title']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
